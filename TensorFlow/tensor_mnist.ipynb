{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorMNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "pccLMyH2icQ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zMNojs7NjkSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d264618a-5df8-4633-a065-c14a344d3e5b"
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_UIXV6nylIDl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a6bxmFmNkuis",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Description\n",
        "The dataset is refer to [this notebook](https://www.kaggle.com/mahmudulhasanshauqi/deep-learning-with-python-chapter-2-ex-1) in kaggle."
      ]
    },
    {
      "metadata": {
        "id": "b1m-jUw7mvmE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PJUDT7BykYy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ed18b6e7-674a-4932-cf53-6d85bb99a044"
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d mustafaali96/mnist -p /content/kaggle"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading mnist.zip to /content/kaggle\n",
            " 46% 5.00M/11.0M [00:00<00:00, 35.2MB/s]\n",
            "100% 11.0M/11.0M [00:00<00:00, 55.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lsFfcLd6nFIO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c17d0a43-47f8-4d4b-baf9-48ca9252241c"
      },
      "cell_type": "code",
      "source": [
        "!unzip /content/kaggle/mnist.zip"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/kaggle/mnist.zip\n",
            "  inflating: mnist.npz               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZvG1LoL-nOJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3c63c6a-eea5-4bed-f078-4fd614e12141"
      },
      "cell_type": "code",
      "source": [
        "!ls ./"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  kaggle  mnist.npz  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nntAgwuvlFdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "885de253-c31d-43b3-bcf8-f162690050c4"
      },
      "cell_type": "code",
      "source": [
        "data = np.load('./mnist.npz')\n",
        "print(data.keys())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['x_test', 'x_train', 'y_train', 'y_test']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mImdQjG_nBFs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ec9d1e02-afea-4f88-f0d4-02694502e3db"
      },
      "cell_type": "code",
      "source": [
        "print(data['x_test'].shape)\n",
        "print(data['x_train'].shape)\n",
        "print(data['y_test'].shape)\n",
        "print(data['y_train'].shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n",
            "(60000, 28, 28)\n",
            "(10000,)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6ypZuya_qPbn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# shuffle data\n",
        "from random import shuffle\n",
        "x_train = data['x_train']\n",
        "y_train = data['y_train']\n",
        "idx_list = [i for i in range(x_train.shape[0])]\n",
        "shuffle(idx_list)\n",
        "x_train_random = x_train[idx_list,:,:]\n",
        "y_train_random = y_train[idx_list]\n",
        "y_onehot = np.zeros([x_train.shape[0],y_train.max()+1],'int')\n",
        "for i in range(x_train.shape[0]):\n",
        "    y_onehot[i][y_train_random[i]]=1\n",
        "# define the batch size\n",
        "batch_size = 60\n",
        "def get_data():\n",
        "    for i in np.arange(0,x_train.shape[0],batch_size):\n",
        "        yield (x_train_random[i:i+batch_size,:,:], y_onehot[i:i+batch_size,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pSh7A1SsxQG-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# shuffle data\n",
        "from random import shuffle\n",
        "x_test = data['x_test']\n",
        "y_test = data['y_test']\n",
        "idx_list = [i for i in range(x_test.shape[0])]\n",
        "shuffle(idx_list)\n",
        "x_test_random = x_test[idx_list,:,:]\n",
        "y_test_random = y_test[idx_list]\n",
        "y_onehottest = np.zeros([x_test.shape[0],y_test.max()+1],'int')\n",
        "for i in range(x_test.shape[0]):\n",
        "    y_onehottest[i][y_test_random[i]]=1\n",
        "# define the batch size\n",
        "batch_size = 100\n",
        "def get_test():\n",
        "    for i in np.arange(0,x_test.shape[0],batch_size):\n",
        "        yield (x_test_random[i:i+batch_size,:,:], y_onehottest[i:i+batch_size,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nal3KV7RoO8n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define Graph"
      ]
    },
    {
      "metadata": {
        "id": "aO6eBkA3n1WW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "W = tf.Variable(tf.zeros([784,10]))\n",
        "b = tf.Variable(tf.zeros([10]))\n",
        "y = tf.nn.softmax(tf.matmul(x,W)+b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u2kR0Xgvo4_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_ = tf.placeholder(\"float\", [None, 10])\n",
        "cross_entropy = -tf.reduce_sum(y_*tf.log(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EhrzmwSopUO3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rUokCqESpfWY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "932rjP6-5dnR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test"
      ]
    },
    {
      "metadata": {
        "id": "m1ySvIfU5ggm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xsYlx4xwpurH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define Session\n",
        "training happen only in a session"
      ]
    },
    {
      "metadata": {
        "id": "kVtSToyHp1zf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "0f7b0d54-fff0-498a-d707-8541496558ba"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for (xs, ys) in get_data():\n",
        "        sess.run(train, feed_dict={x:xs.reshape(60,784), y_:ys})\n",
        "#     print(W.eval())\n",
        "    for (xss, yss) in get_test():\n",
        "        print(sess.run(accuracy, feed_dict={x: xss, y_: yss}))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-5a75b6c33837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(W.eval())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 78400 into shape (60,784)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2Fj_PpEq5Rpx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}